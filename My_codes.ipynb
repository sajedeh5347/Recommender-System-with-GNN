{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the basic functions required to run the codes are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T09:17:34.511454Z",
     "start_time": "2023-05-17T09:17:34.451463Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import sys, os\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm as h_tqdm\n",
    "\n",
    "\n",
    "# data_dir = './data'\n",
    "\n",
    "def check_path(home):\n",
    "    if not os.path.isdir(home):\n",
    "        print(f'Not found dir: {home}, creating it.')\n",
    "        os.mkdir(home)\n",
    "\n",
    "def red_str(s, tofile=False):\n",
    "    s = str(s)\n",
    "    if tofile:\n",
    "        # s = f'**{s}**'\n",
    "        pass\n",
    "    else:\n",
    "        s = f'\\033[1;31;40m{s}\\033[0m'\n",
    "    return s\n",
    "\n",
    "\n",
    "def get_time_str():\n",
    "    return time.strftime('%Y-%m-%d_%H.%M.%S') + str(time.time() % 1)[1:6]\n",
    "\n",
    "\n",
    "def save_json(data, fn, sort_keys=True, indent=None):\n",
    "    with open(fn, 'w') as f:\n",
    "        json.dump(data, f, sort_keys=sort_keys, indent=indent)\n",
    "\n",
    "\n",
    "def load_json(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def gen_data_from_jsonl(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            yield data\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, fn, verbose=1):\n",
    "        self.pre_time = time.time()\n",
    "        self.fn = fn\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fn\n",
    "\n",
    "    def log(self, s='', end='\\n', red=False):\n",
    "        s = str(s)\n",
    "        if self.verbose == 1:\n",
    "            p = red_str(s) if red else s\n",
    "            print(p, end=end)\n",
    "        elif self.verbose == 2:\n",
    "            p = red_str(s, tofile=True) if red else s\n",
    "            print(p, end=end)\n",
    "        now_time = time.time()\n",
    "        s = s + end\n",
    "        if now_time - self.pre_time > 30 * 60:\n",
    "            s = get_time_str() + '\\n' + s\n",
    "            self.pre_time = now_time\n",
    "        with open(self.fn, 'a') as f:\n",
    "            fs = red_str(s, tofile=True) if red else s\n",
    "            f.write(fs)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, min_cnt=1):\n",
    "        self.min_cnt = min_cnt\n",
    "        self.edge_cnt = {}\n",
    "        self.adj = {}\n",
    "        self._nb_edges = 0\n",
    "\n",
    "    def add_edge(self, a, b):\n",
    "        e = (a, b)\n",
    "        self.edge_cnt.setdefault(e, 0)\n",
    "        self.edge_cnt[e] += 1\n",
    "\n",
    "        if self.edge_cnt[e] == self.min_cnt:\n",
    "            self.adj.setdefault(a, [])\n",
    "            self.adj[a].append(b)\n",
    "            self._nb_edges += 1\n",
    "\n",
    "    def has_edge(self, a, b):\n",
    "        cnt = self.edge_cnt.get((a, b), 0)\n",
    "        return cnt >= self.min_cnt\n",
    "\n",
    "    def get_edges(self):\n",
    "        edges = sorted([(a, b) for (a, b), cnt in self.edge_cnt.items() if cnt >= self.min_cnt])\n",
    "        return edges\n",
    "\n",
    "    def get_adj(self, a):\n",
    "        return self.adj.get(a, [])\n",
    "\n",
    "    def nb_edges(self):\n",
    "        return self._nb_edges\n",
    "\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "class Object(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        for name in kwargs:\n",
    "            setattr(self, name, kwargs[name])\n",
    "\n",
    "    def vars(self):\n",
    "        return self.__dict__\n",
    "\n",
    "    def keys(self):\n",
    "        return sorted(self.__dict__.keys())\n",
    "\n",
    "    def values(self, keys=None):\n",
    "        if keys is None:\n",
    "            keys = self.keys()\n",
    "        return [self.__dict__[k] for k in keys]\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def get(self, name, d=None):\n",
    "        return self.__dict__.get(name, d)\n",
    "\n",
    "    def set(self, name, value):\n",
    "        self.__dict__[name] = value\n",
    "\n",
    "    def filter(self, *keys):\n",
    "        ret = Object()\n",
    "        for k in keys:\n",
    "            ret.set(k, self.get(k))\n",
    "        return ret\n",
    "\n",
    "    def update(self, **args):\n",
    "        self.__dict__.update(args)\n",
    "        return self\n",
    "\n",
    "    def setdefault(self, **args):\n",
    "        for k, v in args.items():\n",
    "            if k not in self.__dict__:\n",
    "                self.__dict__[k] = v\n",
    "        return self\n",
    "\n",
    "    def prt_json(self):\n",
    "        d = {}\n",
    "        for k, v in self.__dict__.items():\n",
    "            if type(v) not in (dict, list, int, float, bool, str):\n",
    "                v = str(v)\n",
    "            d[k] = v\n",
    "        return json.dumps(d, indent=2, sort_keys=True)\n",
    "\n",
    "    def prt_line(self):\n",
    "        return json.dumps(self.__dict__, sort_keys=True)\n",
    "\n",
    "    def __str__(self):\n",
    "        lines = []\n",
    "        for k in sorted(self.keys()):\n",
    "            lines.append(f'{k}: {self.get(k)}')\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def format_prt(self):\n",
    "        type_name = type(self).__name__\n",
    "        arg_strings = []\n",
    "        star_args = {}\n",
    "        for arg in self._get_args():\n",
    "            arg_strings.append(repr(arg))\n",
    "        for name, value in self._get_kwargs():\n",
    "            if name.isidentifier():\n",
    "                arg_strings.append('%s=%r' % (name, value))\n",
    "            else:\n",
    "                star_args[name] = value\n",
    "        if star_args:\n",
    "            arg_strings.append('**%s' % repr(star_args))\n",
    "        return '%s(%s)' % (type_name, ', '.join(arg_strings))\n",
    "\n",
    "class AsyncStream:\n",
    "    def __init__(self, stream, max_q_size=1, mode='MT'):\n",
    "        self.stream = stream\n",
    "        self.close = False\n",
    "        if mode == 'MP':\n",
    "            from multiprocessing import Process, Queue\n",
    "            self.q = Queue(max_q_size)\n",
    "            self.p = Process(target=self.task)\n",
    "            self.p.daemon = True\n",
    "            self.p.start()\n",
    "        else:\n",
    "            import threading\n",
    "            from queue import Queue\n",
    "            self.q = Queue(max_q_size)\n",
    "            self.p = threading.Thread(target=self.task)\n",
    "            self.p.daemon = True\n",
    "            self.p.start()\n",
    "\n",
    "    def task(self):\n",
    "        for d in self.stream:\n",
    "            self.q.put(d)\n",
    "        self.q.put(None)\n",
    "\n",
    "    def generator(self):\n",
    "        while True:\n",
    "            d = self.q.get()\n",
    "            if d is None:\n",
    "                break\n",
    "            yield d\n",
    "\n",
    "class my_tqdm:\n",
    "    def __init__(self, desc, total, leave):\n",
    "        self.desc = desc\n",
    "        self.total = total\n",
    "        self.cnt = 0\n",
    "        self.leave = leave\n",
    "        if self.leave:\n",
    "            print(f'>>> begin {self.desc}...')\n",
    "        self.bt = time.time()\n",
    "\n",
    "    def update(self, n):\n",
    "        self.cnt += n\n",
    "\n",
    "    def close(self):\n",
    "        t = time.time() - self.bt\n",
    "        v = self.cnt / t\n",
    "        if self.leave:\n",
    "            print(f'--- {self.desc} end, cnt: {self.cnt}, time: {t:.0f}s, v: {v:.2f}it/s')\n",
    "\n",
    "\n",
    "def tqdm(verbose=None, desc='tqdm', leave=True, total=None):\n",
    "    if verbose is None:\n",
    "        verbose = args.get('verbose', 1)\n",
    "    if verbose == 1:\n",
    "        return h_tqdm(desc=desc, total=total, leave=leave, ncols=90, ascii=True)\n",
    "    return my_tqdm(desc=desc, total=total,  leave=leave)\n",
    "\n",
    "args = Object()\n",
    "run_time_dir = 'run_time'\n",
    "check_path(run_time_dir)\n",
    "\n",
    "data_dir = f'{run_time_dir}/data'\n",
    "log_dir = f'{run_time_dir}/log'\n",
    "save_dir = f'{run_time_dir}/save'\n",
    "\n",
    "check_path(data_dir)\n",
    "check_path(log_dir)\n",
    "check_path(save_dir)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the designed model is implemented. The proposed change in the thesis has been applied using the star_GNN function in the model of the reference article. In fact, by adding this function, the performance of the model has been improved and the fundamental change of the codes has been in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T09:17:40.373458Z",
     "start_time": "2023-05-17T09:17:35.926769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sharif\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, sys, math, os\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import utils\n",
    "from utils import args\n",
    "\n",
    "eps = 1e-7\n",
    "inf = 1e31\n",
    "\n",
    "\n",
    "class Base:\n",
    "    deep = True\n",
    "    args = Object()\n",
    "\n",
    "    # feature: [type..], [tags..], mid\n",
    "    def __init__(self, data):\n",
    "        self.raw_adjs = data.adjs\n",
    "\n",
    "        # self.save_name = f'{utils.save_dir}/{args.run_name}/model.ckpt'\n",
    "        self.save_dir = f'{save_dir}/{args.run_name}'\n",
    "        self.tb_name = f'{save_dir}/{args.run_name}'\n",
    "\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            #tf.random.set_seed(args.seed)\n",
    "            tf.set_random_seed(args.seed)\n",
    "            self.compile()\n",
    "        self.fit_step = 0\n",
    "\n",
    "    def compile(self):\n",
    "        self.make_io()\n",
    "        self.make_model()\n",
    "        if args.run_tb:\n",
    "            self.all_summary = tf.summary.merge_all()\n",
    "            self.tbfw = tf.summary.FileWriter(self.tb_name, self.sess.graph)\n",
    "\n",
    "    def placeholder(self, dtype, shape, name, to_list):\n",
    "        ph = tf.placeholder(dtype, shape, name)\n",
    "        self.placeholder_dict[name] = ph\n",
    "        to_list.append(ph)\n",
    "        return ph\n",
    "\n",
    "    def make_io(self):\n",
    "        self.placeholder_dict = {}\n",
    "        self.inputs = []\n",
    "        L = args.seq_length\n",
    "        self.placeholder(tf.int32, [None, L], 'share_seq', self.inputs)\n",
    "        self.placeholder(tf.int32, [None, L], 'click_seq', self.inputs)\n",
    "\n",
    "        self.placeholder(tf.int32, [None], 'pos', self.inputs)\n",
    "        self.placeholder(tf.int32, [None, None], 'neg', self.inputs)\n",
    "\n",
    "        self.adjs = [\n",
    "            tf.constant(adj, dtype=tf.int32) for adj in self.raw_adjs\n",
    "        ]  # [N, M] * 4, in_0, out_0, in_1, out_1\n",
    "\n",
    "    def get_data_map(self, data):\n",
    "        data_map = dict(zip(self.inputs, data))\n",
    "        return data_map\n",
    "\n",
    "    def make_model(self):\n",
    "        with tf.variable_scope(\n",
    "                'Graph', reuse=tf.AUTO_REUSE,\n",
    "                regularizer=self.l2_loss('all')) as self.graph_scope:\n",
    "            n = args.nb_nodes\n",
    "            k = args.dim_k\n",
    "            self.embedding_matrix = tf.get_variable(name='emb_w', shape=[n, k])\n",
    "            with tf.variable_scope(\n",
    "                    'graph_agg', reuse=tf.AUTO_REUSE) as self.graph_agg_scope:\n",
    "                pass\n",
    "\n",
    "        with tf.variable_scope('Network',\n",
    "                               reuse=tf.AUTO_REUSE,\n",
    "                               regularizer=self.l2_loss('all')):\n",
    "            score, label = self.forward(*self.inputs)\n",
    "            #seq_loss = tf.losses.softmax_cross_entropy(label, score)\n",
    "            seq_loss = tf.losses.mean_squared_error(label, score)\n",
    "            tf.summary.scalar('seq_loss', seq_loss)\n",
    "\n",
    "        self.loss = seq_loss\n",
    "        self.loss += tf.losses.get_regularization_loss()\n",
    "\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=args.lr)\n",
    "        self.minimizer = opt.minimize(self.loss)\n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "        graph_var_list = tf.trainable_variables(scope='^Graph/')\n",
    "        network_var_list = tf.trainable_variables(scope='^Network/')\n",
    "        for v in graph_var_list:\n",
    "            print('graph', v)\n",
    "        for v in network_var_list:\n",
    "            print('network', v)\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.sess = self.get_session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def get_session(self):\n",
    "        gpu_options = tf.GPUOptions(\n",
    "            per_process_gpu_memory_fraction=1,\n",
    "            visible_device_list=args.gpu,\n",
    "            allow_growth=True,\n",
    "        )\n",
    "        config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "        session = tf.Session(config=config)\n",
    "        return session\n",
    "\n",
    "    def fit(self, data):\n",
    "        data = dict(zip(self.inputs, data))\n",
    "        if args.run_tb:\n",
    "            _, loss, summary = self.sess.run(\n",
    "                [self.minimizer, self.loss, self.all_summary], data)\n",
    "            self.tbfw.add_summary(summary, self.fit_step)\n",
    "        else:\n",
    "            _, loss = self.sess.run([self.minimizer, self.loss], data)\n",
    "        self.fit_step += 1\n",
    "        return loss\n",
    "\n",
    "    def topk(self, data):\n",
    "        data = self.get_data_map(data)\n",
    "        return self.sess.run([self.topkV, self.topkI], data)\n",
    "\n",
    "    def save(self):\n",
    "        name = f'{self.save_dir}/model.ckpt'\n",
    "        self.saver.save(self.sess, name)\n",
    "\n",
    "    def restore(self):\n",
    "        name = f'{self.save_dir}/model.ckpt'\n",
    "        try:\n",
    "            self.saver.restore(self.sess, name)\n",
    "        except Exception as e:\n",
    "            print(f'can not restore model: {name}')\n",
    "            raise e\n",
    "\n",
    "    def l2_loss(self, name):\n",
    "        alpha = args.get(f'l2_{name}', 0)\n",
    "        if alpha < 1e-7:\n",
    "            return None\n",
    "        return lambda x: alpha * tf.nn.l2_loss(x)\n",
    "\n",
    "    def Mean(self, seq, seq_length=None, mask=None, name=None):\n",
    "        # seq: (None, L, k), seq_length: (None, ), mask: (None, L)\n",
    "        # ret: (None, k)\n",
    "        if seq_length is None and mask is None:\n",
    "            with tf.variable_scope('Mean'):\n",
    "                return tf.reduce_sum(seq, -2)\n",
    "\n",
    "        with tf.variable_scope('MaskMean'):\n",
    "            if mask is None:\n",
    "                mask = tf.sequence_mask(seq_length,\n",
    "                                        maxlen=tf.shape(seq)[1],\n",
    "                                        dtype=tf.float32)\n",
    "            mask = tf.expand_dims(mask, -1)  # (None, L, 1)\n",
    "            seq = seq * mask\n",
    "            seq = tf.reduce_sum(seq, -2)  # (None, k)\n",
    "            seq = seq / (tf.reduce_sum(mask, -2) + eps)\n",
    "        return seq\n",
    "\n",
    "    def MLP(self, x, fc, activation, name):\n",
    "        with tf.variable_scope(f'MLP_{name}'):\n",
    "            for i in range(len(fc)):\n",
    "                x = tf.layers.dense(x,\n",
    "                                    fc[i],\n",
    "                                    activation=activation,\n",
    "                                    name=f'dense_{i}')\n",
    "        return x\n",
    "\n",
    "    def gate(self, a, b, name):\n",
    "        with tf.variable_scope(name):\n",
    "            alpha = tf.layers.dense(tf.concat([a, b], -1),\n",
    "                                    1,\n",
    "                                    activation=tf.nn.sigmoid,\n",
    "                                    name='gateW')\n",
    "            ret = alpha * a + (1 - alpha) * b\n",
    "        return ret\n",
    "\n",
    "    def star_GNN(self, a , b , c , d , name):\n",
    "        with tf.variable_scope(name):\n",
    "            u = self.gate(a, b, 'merge_share_and_click_seq')\n",
    "            \n",
    "            z_r = self.gate(c , d , 'merge_share_and_click_seqn')\n",
    "            #print(z_r.shape)\n",
    "            #z = tf.layers.dense(tf.concat([\n",
    "             #   tf.reshape(u, [args.dim_k, 1]),\n",
    "             #   tf.reshape(z_r, [args.dim_k, 1])\n",
    "            #], -1),\n",
    "            #                    args.dim_k,\n",
    "            #                    activation=tf.nn.relu)\n",
    "            #z = tf.layers.dense(tf.concat([u,z_r], -1),\n",
    "             #                   args.dim_k,\n",
    "              #                  activation=tf.nn.relu)\n",
    "            z = self.gate(z_r,u, 'merge')\n",
    "            #print(u)\n",
    "            #print(z_r)\n",
    "            return z\n",
    "\n",
    "    def Embedding(self, node, name='node', mask_zero=False):\n",
    "        # node: [BS]\n",
    "        with tf.variable_scope(f'Emb_{name}'):\n",
    "            emb_w = self.embedding_matrix\n",
    "            t = tf.gather(emb_w, node)\n",
    "            if mask_zero:\n",
    "                mask = tf.not_equal(node, 0)\n",
    "                mask = tf.cast(mask, tf.float32)\n",
    "            else:\n",
    "                mask = None\n",
    "        return t, mask\n",
    "\n",
    "\n",
    "    def forward(self, share_seq, click_seq, pos, neg):\n",
    "        pos2 = tf.expand_dims(pos, -1)\n",
    "        nxt = tf.concat([pos2, neg], -1)  # [BS, M + 1]\n",
    "        label = tf.concat([\n",
    "            tf.ones_like(pos2, dtype=tf.int32),\n",
    "            tf.zeros_like(neg, dtype=tf.int32)\n",
    "        ], -1)  # [BS, M + 1]\n",
    "\n",
    "        seq_emb = self.merge_seq(share_seq, click_seq)\n",
    "        seq_emb = tf.layers.dense(seq_emb,args.dim_k,name='dense_W',use_bias=False)\n",
    "        \n",
    "        print('seq_emb',seq_emb.shape)\n",
    "        print('embedding_matrix',self.embedding_matrix.shape)\n",
    "        score = tf.matmul(seq_emb, self.embedding_matrix, transpose_b=True)\n",
    "        #print('self.embedding_matrix', type(self.embedding_matrix))\n",
    "        #score = tf.layers.dense(tf.concat([seq_emb,tf.transpose(self.embedding_matrix)], -1),52740,activation=tf.nn.relu)\n",
    "        #print('score', score)\n",
    "\n",
    "        topk = tf.math.top_k(score, k=500)\n",
    "        self.topkV = topk.values\n",
    "        self.topkI = topk.indices\n",
    "\n",
    "        nxt_embs, _ = self.Embedding(nxt)  # [BS, M + 1, k]\n",
    "        nxt_score = tf.reduce_sum(tf.expand_dims(seq_emb, 1) * nxt_embs, -1)\n",
    "        return nxt_score, label\n",
    "\n",
    "    def node_embedding(self, node):\n",
    "        # node: [BS, L]\n",
    "        embs, mask = self.Embedding(node, mask_zero=True)\n",
    "        return embs, mask   \n",
    "\n",
    "    def merge_seq(self, share_seq, click_seq):\n",
    "        with tf.variable_scope(f'merge_seq', reuse=tf.AUTO_REUSE):\n",
    "            share_seq_embs, share_mask = self.node_embedding(share_seq)\n",
    "            share_emb = self.seq_embedding(share_seq_embs, share_mask, 'share')\n",
    "            #print('share_emb',share_emb.shape)\n",
    "            click_seq_embs, click_mask = self.node_embedding(click_seq)\n",
    "            click_emb = self.seq_embedding(click_seq_embs, click_mask, 'click')\n",
    "            #print('click_emb',click_emb.shape)\n",
    "            \n",
    "            share_emb_n, _ = self.Embedding(share_seq[:,-1], mask_zero=False)\n",
    "            #print('share_emb_n',share_emb_n.shape)\n",
    "            click_emb_n, _ = self.Embedding(click_seq[:,-1], mask_zero=False)\n",
    "            #print('click_emb_n',click_emb_n.shape)\n",
    "            \n",
    "            #u = self.gate(share_emb, click_emb, 'merge_share_and_click_seq')\n",
    "    \n",
    "            #z_r = self.gate(share_emb_n,click_emb_n,'merge_share_and_click_seq_n')\n",
    "\n",
    "            emb = self.star_GNN(share_emb , click_emb , share_emb_n , click_emb_n , 'user_emb')\n",
    "            #print('z_r',z_r.shape)\n",
    "            #print('u',u.shape)\n",
    "            #emb=self.gate(z_r, u, 'merge')\n",
    "            #print(emb.shape)\n",
    "            return emb\n",
    "\n",
    "    def seq_embedding(self, seq, mask, name):\n",
    "        # seq: [BS, L, k]\n",
    "        with tf.variable_scope(f'seq_embedding_{name}', reuse=tf.AUTO_REUSE):\n",
    "            seq_emb = self.Mean(seq, mask=mask)\n",
    "        return seq_emb\n",
    "\n",
    "\n",
    "class GNN(Base):\n",
    "    args = Base.args.copy().update()\n",
    "\n",
    "    def node_embedding(self, node):\n",
    "        # node: [BS, L]\n",
    "        with tf.variable_scope(self.graph_scope):\n",
    "            embs, mask = self.node_list_aggregate(node,\n",
    "                                                  depth=args.gnnd,\n",
    "                                                  mask_zero=True)  # [BS, L, k]\n",
    "        return embs, mask\n",
    "\n",
    "    def node_embedding2(self, node):\n",
    "        # node: [BS, L]\n",
    "        with tf.variable_scope(self.graph_scope):\n",
    "            embs, mask = self.node_list_aggregate2(node,\n",
    "                                                  depth=args.gnnd,\n",
    "                                                  mask_zero=True)  # [BS, L, k]\n",
    "        return embs, mask\n",
    "    \n",
    "    def node_list_aggregate2(self, nodes, depth, mask_zero, name='share'):\n",
    "        # nodes: [BS, M]\n",
    "        bs = tf.shape(nodes)[0]\n",
    "        m = tf.shape(nodes)[0]\n",
    "        nodes = tf.reshape(nodes, [bs * m])\n",
    "        emb, mask = self.single_node_aggregate2(nodes, depth, mask_zero, name)\n",
    "        # k = tf.shape(emb)[1]\n",
    "        k = args.dim_k\n",
    "        emb = tf.reshape(emb, [bs, m, k])\n",
    "        if mask is not None:\n",
    "            mask = tf.reshape(mask, [bs, m])\n",
    "        return emb, mask\n",
    "\n",
    "    def node_list_aggregate(self, nodes, depth, mask_zero, name='share'):\n",
    "        # nodes: [BS, M]\n",
    "        bs = tf.shape(nodes)[0]\n",
    "        m = tf.shape(nodes)[1]\n",
    "        nodes = tf.reshape(nodes, [bs * m])\n",
    "        emb, mask = self.single_node_aggregate(nodes, depth, mask_zero, name)\n",
    "        # k = tf.shape(emb)[1]\n",
    "        k = args.dim_k\n",
    "        emb = tf.reshape(emb, [bs, m, k])\n",
    "        if mask is not None:\n",
    "            mask = tf.reshape(mask, [bs, m])\n",
    "        return emb, mask\n",
    "\n",
    "    def _agg(self, cur, nxt, mask, name):\n",
    "        return self.Mean(nxt, mask=mask)\n",
    "\n",
    "    def _merge(self, cur, nxt):\n",
    "        return cur + nxt\n",
    "\n",
    "    def single_node_aggregate(self, node, depth, mask_zero, name='share'):\n",
    "        # node: [BS], adj: [N, M]\n",
    "        if depth <= 0:\n",
    "            return self.Embedding(node, mask_zero=mask_zero)\n",
    "        with tf.variable_scope(f'agg{depth}layer_{name}'):\n",
    "            bs = tf.shape(node)[0]\n",
    "            cur, cur_mask = self.single_node_aggregate(node, depth - 1,\n",
    "                                                       mask_zero,\n",
    "                                                       name)  # [BS, k]\n",
    "\n",
    "            nxt_in_0 = tf.gather(self.adjs[0], node)  # [BS, M]\n",
    "            nxt_in_0, nxt_in_0_mask = self.node_list_aggregate(nxt_in_0, depth - 1, mask_zero, name)  # [BS, M, k]\n",
    "\n",
    "            nxt_out_0 = tf.gather(self.adjs[1], node)  # [BS, M]\n",
    "            nxt_out_0, nxt_out_0_mask = self.node_list_aggregate(nxt_out_0, depth - 1, mask_zero, name)  # [BS, M, k]\n",
    "\n",
    "            nxt_in_1 = tf.gather(self.adjs[2], node)  # [BS, M]\n",
    "            nxt_in_1, nxt_in_1_mask = self.node_list_aggregate(nxt_in_1, depth - 1, mask_zero, name)  # [BS, M, k]\n",
    "\n",
    "            nxt_out_1 = tf.gather(self.adjs[3], node)  # [BS, M]\n",
    "            nxt_out_1, nxt_out_1_mask = self.node_list_aggregate(nxt_out_1, depth - 1, mask_zero, name)  # [BS, M, k]\n",
    "\n",
    "            h = self._aggregate4(cur, nxt_in_0, nxt_in_0_mask, nxt_out_0,nxt_out_0_mask, nxt_in_1, nxt_in_1_mask,nxt_out_1, nxt_out_1_mask, name)  # [BS, k]\n",
    "            return h, cur_mask\n",
    "        \n",
    "    def single_node_aggregate2(self, node, depth, mask_zero, name='share'):\n",
    "        # node: [BS], adj: [N, M]\n",
    "        if depth <= 0:\n",
    "            return self.Embedding(node, mask_zero=mask_zero)\n",
    "        with tf.variable_scope(f'agg{depth}layer_{name}'):\n",
    "            bs = tf.shape(node)[0]\n",
    "            cur, cur_mask = self.single_node_aggregate2(node, depth - 1,\n",
    "                                                       mask_zero,\n",
    "                                                       name)  # [BS, k]\n",
    "\n",
    "            nxt_in_0 = tf.gather(self.adjs[0], node)  # [BS, M]\n",
    "            nxt_in_0, nxt_in_0_mask = self.node_list_aggregate2(nxt_in_0, depth - 1, mask_zero, name)  # [BS, M, k]\n",
    "\n",
    "            nxt_out_0 = tf.gather(self.adjs[1], node)  # [BS, M]\n",
    "            nxt_out_0, nxt_out_0_mask = self.node_list_aggregate2(nxt_out_0, depth - 1, mask_zero, name)  # [BS, M, k]\n",
    "\n",
    "            nxt_in_1 = tf.gather(self.adjs[2], node)  # [BS, M]\n",
    "            nxt_in_1, nxt_in_1_mask = self.node_list_aggregate2(nxt_in_1, depth - 1, mask_zero, name)  # [BS, M, k]\n",
    "\n",
    "            nxt_out_1 = tf.gather(self.adjs[3], node)  # [BS, M]\n",
    "            nxt_out_1, nxt_out_1_mask = self.node_list_aggregate2(nxt_out_1, depth - 1, mask_zero, name)  # [BS, M, k]\n",
    "\n",
    "            h = self._aggregate4(cur, nxt_in_0, nxt_in_0_mask, nxt_out_0,nxt_out_0_mask, nxt_in_1, nxt_in_1_mask,nxt_out_1, nxt_out_1_mask, name)  # [BS, k]\n",
    "            return h, cur_mask\n",
    "\n",
    "    def _aggregate4(self, cur, nxt_in_0, nxt_in_0_mask, nxt_out_0,nxt_out_0_mask, nxt_in_1, nxt_in_1_mask, nxt_out_1,nxt_out_1_mask, name):\n",
    "        with tf.variable_scope(self.graph_agg_scope):\n",
    "            nxt_in_0 = self._agg(cur, nxt_in_0, nxt_in_0_mask, 'agg_in')\n",
    "            nxt_out_0 = self._agg(cur, nxt_out_0, nxt_out_0_mask, 'agg_out')\n",
    "            nxt_in_1 = self._agg(cur, nxt_in_1, nxt_in_1_mask, 'agg_in')\n",
    "            nxt_out_1 = self._agg(cur, nxt_out_1, nxt_out_1_mask, 'agg_out')\n",
    "\n",
    "            nxt = nxt_in_0 + nxt_out_0 + nxt_in_1 + nxt_out_1\n",
    "            o = self._merge(cur, nxt)\n",
    "            return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the codes of this part, we enter the data to train the model and simultaneously create the graph, the graph adjacency matrix and the feature matrix of the vertices. Due to the large amount of data used, we encountered some challenges in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T09:17:40.977492Z",
     "start_time": "2023-05-17T09:17:40.930319Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, sys, math, os\n",
    "import json\n",
    "import pickle\n",
    "import copy\n",
    "import utils\n",
    "import re\n",
    "from utils import args, tqdm\n",
    "import time\n",
    "\n",
    "data_home = 'run_time/data'\n",
    "class DatasetReader:\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "        if ds == 'yc64' or ds == 'test':\n",
    "            self.N = 144527\n",
    "            self.reader = self.yc64\n",
    "            self.min_ts, self.max_ts = 1411604904, 1412017199\n",
    "        elif ds == 'yc4':\n",
    "            self.N = 2312432\n",
    "            self.reader = self.yc4\n",
    "            self.min_ts, self.max_ts = 1408507486, 1412017199\n",
    "        elif ds == 'yc':\n",
    "            self.N = 9249729\n",
    "            self.reader = self.yc\n",
    "            self.min_ts, self.max_ts = 1396292400, 1412017199\n",
    "\n",
    "        dt = self.max_ts - self.min_ts\n",
    "        dt2 = dt // 7 * 3\n",
    "        self.train_ts = self.min_ts + dt2 * 2\n",
    "\n",
    "    def yc(self, frac=1):\n",
    "        pbar = tqdm(desc='read data', total=self.N)\n",
    "        f = open(f'{data_home}/yc_1_{frac}/data.txt', 'r')\n",
    "        for line in f:\n",
    "            pbar.update(1)\n",
    "            line = line[:-1]\n",
    "            sid, vid_list_str = line.split()\n",
    "            vid_list = []\n",
    "            for vid in vid_list_str.split(','):\n",
    "                vid, cls, ts = vid.split(':')\n",
    "                cls = int(cls)  # cls: 0, 1, 2, ...\n",
    "                ts = int(ts)\n",
    "                vid_list.append([vid, cls, ts])\n",
    "            yield vid_list\n",
    "        f.close()\n",
    "        pbar.close()\n",
    "\n",
    "    def yc4(self):\n",
    "        yield from self.yc(4)\n",
    "\n",
    "    def yc64(self):\n",
    "        yield from self.yc(64)\n",
    "\n",
    "    def wx(self):\n",
    "        pass\n",
    "\n",
    "class DataProcess:\n",
    "    def __init__(self, ds, adj_length, seq_length):\n",
    "        self.ds = ds\n",
    "        # self.adj_length = adj_length\n",
    "        # self.seq_length = seq_length\n",
    "\n",
    "        self.vid2node = {}\n",
    "        self.vid2node['[MASK]'] = 0\n",
    "\n",
    "        self.DR = DatasetReader(ds)\n",
    "        self.G_in, self.G_out, self.train_data, self.test_data = self.build_graph(seq_length)\n",
    "\n",
    "        rdm = np.random.RandomState(777)\n",
    "        rdm.shuffle(self.train_data)\n",
    "\n",
    "        rdm = np.random.RandomState(333)\n",
    "        rdm.shuffle(self.test_data)\n",
    "\n",
    "        args.update(nb_nodes=len(self.vid2node))\n",
    "        args.update(nb_edges_0=self.G_in[0].nb_edges())\n",
    "        args.update(nb_edges_1=self.G_in[1].nb_edges())\n",
    "\n",
    "        self.adj_in_0 = self.build_adj(self.G_in[0], adj_length)\n",
    "        self.adj_out_0 = self.build_adj(self.G_out[0], adj_length)\n",
    "        self.adj_in_1 = self.build_adj(self.G_in[1], adj_length)\n",
    "        self.adj_out_1 = self.build_adj(self.G_out[1], adj_length)\n",
    "\n",
    "        self.adjs_tmp = [self.adj_in_0, self.adj_out_0, self.adj_in_1, self.adj_out_1]\n",
    "        self.adjs = [a[0] for a in self.adjs_tmp]\n",
    "\n",
    "    def build_graph(self, seq_length):\n",
    "        test_seq = []\n",
    "        G_in = [Graph() for i in range(2)]\n",
    "        G_out = [Graph() for i in range(2)]\n",
    "        train_data = []\n",
    "        test_data = []\n",
    "        for num_data, vid_list in enumerate(self.DR.reader()):\n",
    "\n",
    "            vid_list_for_graph = [[] for i in range(2)]\n",
    "            vid_list_for_train = [[] for i in range(2)]\n",
    "            first_pos = [{} for i in range(2)]\n",
    "\n",
    "            for i, (vid, typ, ts) in enumerate(vid_list):\n",
    "                if vid not in self.vid2node:\n",
    "                    self.vid2node[vid] = len(self.vid2node)\n",
    "\n",
    "                for_train = False\n",
    "                if ts < self.DR.train_ts:\n",
    "                    for_train = True\n",
    "\n",
    "                if for_train:\n",
    "                    vid_list_for_graph[typ].append(vid)\n",
    "\n",
    "                if typ == 0 and vid not in first_pos[0]:\n",
    "                    share_history = vid_list_for_train[0]\n",
    "                    if vid not in first_pos[1]:\n",
    "                        click_history = vid_list_for_train[1]\n",
    "                    else:\n",
    "                        k = first_pos[1][vid]\n",
    "                        click_history = vid_list_for_train[1][:k]\n",
    "\n",
    "                    if len(click_history) >= 5 and len(share_history) >= 1:\n",
    "                        seq_share = [share_history[-seq_length: ], click_history[-seq_length: ], vid]\n",
    "                        if for_train:\n",
    "                            train_data.append(seq_share)\n",
    "                        else:\n",
    "                            test_data.append(seq_share)\n",
    "\n",
    "                if vid not in first_pos[typ]:\n",
    "                    first_pos[typ][vid] = len(vid_list_for_train[typ])\n",
    "                vid_list_for_train[typ].append(vid)\n",
    "\n",
    "            for typ in range(2):\n",
    "                for i, vid in enumerate(vid_list_for_graph[typ]):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    now_node = self.vid2node[vid]\n",
    "                    pre_node = self.vid2node[vid_list_for_graph[typ][i - 1]]\n",
    "                    if now_node != pre_node:\n",
    "                        G_in[typ].add_edge(pre_node, now_node)\n",
    "                        G_out[typ].add_edge(now_node, pre_node)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        return G_in, G_out, train_data, test_data\n",
    "\n",
    "\n",
    "    def build_adj(self, G, M):\n",
    "        # M: number of adj per node\n",
    "        N = args.nb_nodes\n",
    "        # adj shape: [N, M]\n",
    "        adj = [None] * N\n",
    "        adj[0] = [0] * M\n",
    "\n",
    "        w = [None] * N\n",
    "        w[0] = [0] * M\n",
    "\n",
    "        rdm = np.random.RandomState(555)\n",
    "        pbar = tqdm(total=N - 1, desc='building adj')\n",
    "        for node in range(1, N):\n",
    "            pbar.update(1)\n",
    "            adj_list = G.get_adj(node)\n",
    "            if len(adj_list) > M:\n",
    "                adj_list = rdm.choice(adj_list, size=M, replace=False).tolist()\n",
    "            mask = [0] * (M - len(adj_list))\n",
    "            adj_list = adj_list[:] + mask\n",
    "            adj[node] = adj_list\n",
    "            w_list = [G.edge_cnt.get((node, x), 0) for x in adj_list]\n",
    "            w[node] = w_list\n",
    "        pbar.close()\n",
    "        return [adj, w]\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.dp = DataProcess(args.ds, args.adj_length, args.seq_length)\n",
    "\n",
    "        self.adjs = self.dp.adjs\n",
    "        self.vid2node = self.dp.vid2node\n",
    "\n",
    "        self.load_data()\n",
    "        self.status = 'train'\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = self.dp.train_data + self.dp.test_data\n",
    "        nb_train = len(self.dp.train_data)\n",
    "        nb_non_train = len(self.dp.test_data)\n",
    "        nb_vali = nb_non_train // 3\n",
    "        nb_test = nb_non_train - nb_vali\n",
    "\n",
    "        nb_data = len(self.data)\n",
    "        assert nb_data > 0\n",
    "        args.update(nb_data=nb_data, nb_train=nb_train, nb_vali=nb_vali, nb_test=nb_test)\n",
    "\n",
    "    def pad_seq(self, node_list):\n",
    "        L = args.seq_length\n",
    "        if len(node_list) < L:\n",
    "            node_list = node_list + [0] * (L - len(node_list))\n",
    "        return node_list\n",
    "\n",
    "    def sample_neg(self, pos, rdm):\n",
    "        neg = set()\n",
    "        while len(neg) < args.num_neg:\n",
    "            n = rdm.randint(args.nb_nodes)\n",
    "            if n != 0 and n != pos and n not in neg:\n",
    "                neg.add(n)\n",
    "        neg = sorted(neg)\n",
    "        return neg\n",
    "\n",
    "    def get_data_by_idx(self, idx, rdm):\n",
    "        share_history, click_history, pos = self.data[idx]\n",
    "        pos = self.vid2node[pos]\n",
    "\n",
    "        share_seq = [self.vid2node[vid] for vid in share_history]\n",
    "        click_seq = [self.vid2node[vid] for vid in click_history]\n",
    "\n",
    "        share_list = self.pad_seq(share_seq)\n",
    "        click_list = self.pad_seq(click_seq)\n",
    "\n",
    "        ret = [share_list, click_list, pos]\n",
    "\n",
    "        if self.status == 'train':\n",
    "            neg = self.sample_neg(pos, rdm)\n",
    "            ret.append(neg)\n",
    "        return ret\n",
    "\n",
    "    def get_batch_by_idxs(self, idxs, rdm=None):\n",
    "        data = None\n",
    "        for idx in idxs:\n",
    "            d = self.get_data_by_idx(idx, rdm)\n",
    "            n = len(d)\n",
    "            if data is None:\n",
    "                data = [[] for _ in range(n)]\n",
    "            for i in range(n):\n",
    "                data[i].append(d[i])\n",
    "\n",
    "        # data: [0-seq, 1-typ, 2-len, 3-nxt, 4-label]\n",
    "        batch = [np.array(d) for d in data]\n",
    "        return batch\n",
    "\n",
    "    def gen_train_batch_for_train(self, batch_size):\n",
    "        rdm = np.random.RandomState(333)\n",
    "        while True:\n",
    "            idxs = list(range(args.nb_train))\n",
    "            rdm.shuffle(idxs)\n",
    "            for i in range(0, args.nb_train, batch_size):\n",
    "                batch = self.get_batch_by_idxs(idxs[i: i + batch_size], rdm)\n",
    "                yield batch\n",
    "\n",
    "    def get_data_idxs(self, name):\n",
    "        if name == 'train':\n",
    "            return 0, args.nb_train\n",
    "        if name == 'vali':\n",
    "            return args.nb_train, args.nb_train + args.nb_vali\n",
    "        if name == 'test':\n",
    "            return args.nb_train + args.nb_vali, args.nb_data\n",
    "\n",
    "    def gen_metric_batch(self, name, batch_size):\n",
    "        self.status = 'metric'\n",
    "        begin_idx, end_idx = self.get_data_idxs(name)\n",
    "        yield from self.gen_data_batch(begin_idx, end_idx, batch_size)\n",
    "        self.status = 'train'\n",
    "\n",
    "    def gen_all_batch(self, batch_size):\n",
    "        begin_idx = 0\n",
    "        end_idx = args.nb_data\n",
    "        yield from self.gen_data_batch(begin_idx, end_idx, batch_size)\n",
    "\n",
    "    def gen_data_batch(self, begin_idx, end_idx, batch_size):\n",
    "        for i in range(begin_idx, end_idx, batch_size):\n",
    "            a, b = i, min(end_idx, i + batch_size)\n",
    "            batch = self.get_batch_by_idxs(range(a, b))\n",
    "            yield batch\n",
    "\n",
    "\n",
    "    def metric(self, pred_list, true_vid):\n",
    "        pred_list = np.array(pred_list)\n",
    "        true_vid = np.expand_dims(np.array(true_vid), -1)\n",
    "        print(pred_list.shape)\n",
    "        print(true_vid.shape)\n",
    "\n",
    "        k = 100\n",
    "        acc_ar = (pred_list == true_vid)[:, :k]  # [BS, K]\n",
    "        acc = acc_ar.sum(-1)\n",
    "\n",
    "        rank = np.argmax(acc_ar[:, :k], -1) + 1\n",
    "        mrr = (acc / rank).mean()\n",
    "        ndcg = (acc / np.log2(rank + 1)).mean()\n",
    "\n",
    "        acc = acc.mean()\n",
    "        # print(acc_ar)\n",
    "        # print(mrr)\n",
    "        # input()\n",
    "        acc *= 100\n",
    "        mrr *= 100\n",
    "        ndcg *= 100\n",
    "        ret = acc\n",
    "        return ret, '{:.3f},{:.4f},{:.4f}'.format(acc, mrr, ndcg)\n",
    "\n",
    "\n",
    "def main():\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model training process is defined using the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T09:17:42.313115Z",
     "start_time": "2023-05-17T09:17:41.581936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world, Train.py\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import sys\n",
    "import utils\n",
    "from utils import args, tqdm\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, Model, data):\n",
    "        self.data = data\n",
    "        self.build_model(Model)\n",
    "        self.has_train = False\n",
    "\n",
    "    def build_model(self, Model):\n",
    "        self.model = Model(self.data)\n",
    "\n",
    "    def train(self):\n",
    "        brk = 0\n",
    "        best_vali = 0\n",
    "        data_generator = self.data.gen_train_batch_for_train(args.batch_size)\n",
    "        for ep in range(args.epochs):\n",
    "            pbar = tqdm(total=args.nb_vali_step, desc='training', leave=False)\n",
    "            loss = []\n",
    "            t0 = time.time()\n",
    "            for _ in range(args.nb_vali_step):\n",
    "                data = next(data_generator)\n",
    "                _loss = self.model.fit(data)\n",
    "\n",
    "                loss.append(_loss)\n",
    "                pbar.update(1)\n",
    "            pbar.close()\n",
    "            train_time = time.time() - t0\n",
    "\n",
    "            vali_v, vali_str = self.metric('vali')\n",
    "            if vali_v > best_vali:\n",
    "                brk = 0\n",
    "                best_vali = vali_v\n",
    "                self.model.save()\n",
    "            else:\n",
    "                brk += 1\n",
    "            red = (brk == 0)\n",
    "\n",
    "            msg = f'#{ep + 1}/{args.epochs} loss: {np.mean(loss):.5f}, brk: {brk}, vali: {vali_str}'\n",
    "            if args.show_test and args.nb_test > 0:\n",
    "                _, test_str = self.metric('test')\n",
    "                msg = f'{msg}, test: {test_str}'\n",
    "            vali_time = time.time() - t0 - train_time\n",
    "            msg = f'{msg}, time: {train_time:.0f}s,{vali_time:.0f}s'\n",
    "\n",
    "            args.log.log(msg, red=red)\n",
    "\n",
    "            if ep < 60:\n",
    "                brk = 0\n",
    "            if brk >= args.early_stopping:\n",
    "                break\n",
    "            self.has_train = True\n",
    "\n",
    "    def final_test(self):\n",
    "        self.model.restore()\n",
    "        _, ret = self.metric('test')\n",
    "        return ret\n",
    "\n",
    "\n",
    "    def metric(self, name):\n",
    "        data_gen = self.data.gen_metric_batch(name, batch_size=256)\n",
    "        pred_list, true_vid = self.topk(data_gen)\n",
    "\n",
    "        pred_list = np.array(pred_list)\n",
    "        true_vid = np.expand_dims(np.array(true_vid), -1)\n",
    "\n",
    "        k = 100\n",
    "        acc_ar = (pred_list == true_vid)[:, :k]  # [BS, K]\n",
    "        acc = acc_ar.sum(-1)\n",
    "\n",
    "        rank = np.argmax(acc_ar[:, :k], -1) + 1\n",
    "        mrr = (acc / rank).mean()\n",
    "        ndcg = (acc / np.log2(rank + 1)).mean()\n",
    "\n",
    "        acc = acc.mean()\n",
    "        # print(acc_ar)\n",
    "        # print(mrr)\n",
    "        # input()\n",
    "        acc *= 100\n",
    "        mrr *= 100\n",
    "        ndcg *= 100\n",
    "        ret = acc\n",
    "        # ret = acc + mrr * 10 + ndcg * 5\n",
    "        # ret = acc + mrr + ndcg\n",
    "        # return ret, 'HR%:{:.3f},MRR%:{:.4f},NDCG%:{:.4f}'.format(acc, mrr, ndcg)\n",
    "        return ret, '{:.3f},{:.4f},{:.4f}'.format(acc, mrr, ndcg)\n",
    "\n",
    "    def topk(self, data_gen):\n",
    "        pred_list = []\n",
    "        true_vid = []\n",
    "        cnt = 0\n",
    "        pbar = tqdm(desc='predicting...', leave=False)\n",
    "        for data in data_gen:\n",
    "            v, i = self.model.topk(data)\n",
    "            pred_list.extend(i.tolist())\n",
    "            true_vid.extend(data[2])\n",
    "            pbar.update(1)\n",
    "            cnt += 1\n",
    "            if args.run_test and cnt > 3:\n",
    "                break\n",
    "        pbar.close()\n",
    "        return pred_list, true_vid\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('hello world, Train.py')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we start the training process by determining the adjustable hyperparameter values of the model, for example, adjusting the depth of the neural network of the graph used or the size of the mini-Batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:11:32.106213Z",
     "start_time": "2023-05-17T09:17:42.876096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sharif\\Desktop\\new_project\\MGNN-SPred-master(1)\\MGNN-SPred-master\n",
      "adj_length: 22\n",
      "batch_size: 64\n",
      "dim_k: 64\n",
      "ds: yc\n",
      "early_stopping: 30\n",
      "epochs: 100\n",
      "gnnd: 1\n",
      "gpu: 0\n",
      "l2_all: 0\n",
      "lr: 0.001\n",
      "model: GNN\n",
      "msg: \n",
      "nb_vali_step: 500\n",
      "num_neg: 20\n",
      "run_on_yard: True\n",
      "run_tb: False\n",
      "run_test: False\n",
      "seed: 123456\n",
      "seq_length: 20\n",
      "show_test: False\n",
      "verbose: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read data: 100%|#############################| 9249729/9249729 [02:03<00:00, 74786.45it/s]\n",
      "building adj: 100%|#############################| 52739/52739 [00:00<00:00, 141759.52it/s]\n",
      "building adj: 100%|#############################| 52739/52739 [00:00<00:00, 141000.94it/s]\n",
      "building adj: 100%|##############################| 52739/52739 [00:01<00:00, 29948.33it/s]\n",
      "building adj: 100%|##############################| 52739/52739 [00:01<00:00, 40945.99it/s]\n",
      "<ipython-input-2-96b204ebe9d4>:173: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  alpha = tf.layers.dense(tf.concat([a, b], -1),\n",
      "<ipython-input-2-96b204ebe9d4>:222: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  seq_emb = tf.layers.dense(seq_emb,args.dim_k,name='dense_W',use_bias=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_emb (?, 64)\n",
      "embedding_matrix (52740, 64)\n",
      "graph <tf.Variable 'Graph/emb_w:0' shape=(52740, 64) dtype=float32_ref>\n",
      "network <tf.Variable 'Network/merge_seq/user_emb/merge_share_and_click_seq/gateW/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
      "network <tf.Variable 'Network/merge_seq/user_emb/merge_share_and_click_seq/gateW/bias:0' shape=(1,) dtype=float32_ref>\n",
      "network <tf.Variable 'Network/merge_seq/user_emb/merge_share_and_click_seqn/gateW/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
      "network <tf.Variable 'Network/merge_seq/user_emb/merge_share_and_click_seqn/gateW/bias:0' shape=(1,) dtype=float32_ref>\n",
      "network <tf.Variable 'Network/merge_seq/user_emb/merge/gateW/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
      "network <tf.Variable 'Network/merge_seq/user_emb/merge/gateW/bias:0' shape=(1,) dtype=float32_ref>\n",
      "network <tf.Variable 'Network/dense_W/kernel:0' shape=(64, 64) dtype=float32_ref>\n",
      "2023-05-17_12.49.56.1534 run_time/log/2023-05-17_12.49.50.4390-GNN-yc.log ----- start!, pid: 8780\n",
      "argv: C:\\Users\\Sharif\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\Sharif\\AppData\\Roaming\\jupyter\\runtime\\kernel-88384887-b3bb-4f9d-ad61-5645a00344e1.json\n",
      "log_fn: run_time/log/2023-05-17_12.49.50.4390-GNN-yc.log\n",
      "args: {\n",
      "  \"adj_length\": 22,\n",
      "  \"batch_size\": 64,\n",
      "  \"dim_k\": 64,\n",
      "  \"ds\": \"yc\",\n",
      "  \"early_stopping\": 30,\n",
      "  \"epochs\": 100,\n",
      "  \"gnnd\": 1,\n",
      "  \"gpu\": \"0\",\n",
      "  \"l2_all\": 0,\n",
      "  \"log\": \"run_time/log/2023-05-17_12.49.50.4390-GNN-yc.log\",\n",
      "  \"lr\": 0.001,\n",
      "  \"min_epochs\": 6,\n",
      "  \"model\": \"GNN\",\n",
      "  \"msg\": \"\",\n",
      "  \"nb_data\": 201961,\n",
      "  \"nb_edges_0\": 225873,\n",
      "  \"nb_edges_1\": 3277074,\n",
      "  \"nb_nodes\": 52740,\n",
      "  \"nb_test\": 25973,\n",
      "  \"nb_train\": 163002,\n",
      "  \"nb_vali\": 12986,\n",
      "  \"nb_vali_step\": 500,\n",
      "  \"num_neg\": 20,\n",
      "  \"pid\": 8780,\n",
      "  \"run_name\": \"2023-05-17_12.49.50.4390-GNN-yc\",\n",
      "  \"run_on_yard\": true,\n",
      "  \"run_tb\": false,\n",
      "  \"run_test\": false,\n",
      "  \"seed\": 123456,\n",
      "  \"seq_length\": 20,\n",
      "  \"show_test\": false,\n",
      "  \"verbose\": 1\n",
      "}\n",
      "Model: GNN\n",
      "begin time: 2023-05-17_12.49.56.1534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#1/100 loss: 0.02902, brk: 0, vali: 5.236,0.2344,1.0685, time: 59s,10s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#2/100 loss: 0.02265, brk: 0, vali: 11.204,0.6959,2.4839, time: 60s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3/100 loss: 0.02019, brk: 1, vali: 11.150,0.9260,2.7147, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#4/100 loss: 0.01847, brk: 0, vali: 15.170,1.2981,3.7317, time: 61s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#5/100 loss: 0.01734, brk: 0, vali: 16.202,1.3888,4.0131, time: 61s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#6/100 loss: 0.01607, brk: 0, vali: 16.995,1.4580,4.1570, time: 60s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#7/100 loss: 0.01583, brk: 0, vali: 19.259,1.5522,4.6593, time: 61s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#8/100 loss: 0.01579, brk: 0, vali: 20.661,1.8270,5.1608, time: 60s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#9/100 loss: 0.01544, brk: 1, vali: 20.314,1.8427,5.1452, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#10/100 loss: 0.01514, brk: 0, vali: 21.847,1.9518,5.4914, time: 56s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#11/100 loss: 0.01410, brk: 0, vali: 21.939,2.1016,5.6348, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#12/100 loss: 0.01374, brk: 0, vali: 22.909,2.1788,5.8711, time: 58s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#13/100 loss: 0.01399, brk: 0, vali: 22.955,2.0240,5.7744, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#14/100 loss: 0.01398, brk: 1, vali: 22.902,2.1935,5.9354, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#15/100 loss: 0.01394, brk: 0, vali: 23.325,2.3606,6.0899, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#16/100 loss: 0.01277, brk: 1, vali: 23.148,2.4104,6.1668, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#17/100 loss: 0.01279, brk: 0, vali: 23.464,2.3648,6.1771, time: 56s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#18/100 loss: 0.01279, brk: 0, vali: 23.649,2.4897,6.3172, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#19/100 loss: 0.01298, brk: 1, vali: 23.471,2.6717,6.4527, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#20/100 loss: 0.01309, brk: 1, vali: 23.248,2.5363,6.3081, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#21/100 loss: 0.01216, brk: 1, vali: 23.595,2.6647,6.4727, time: 58s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#22/100 loss: 0.01199, brk: 0, vali: 23.856,2.7464,6.5899, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#23/100 loss: 0.01214, brk: 0, vali: 24.064,2.7563,6.6530, time: 57s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#24/100 loss: 0.01224, brk: 1, vali: 24.064,2.7837,6.6978, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#25/100 loss: 0.01247, brk: 1, vali: 23.795,2.5879,6.4813, time: 56s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#26/100 loss: 0.01174, brk: 0, vali: 24.372,2.8695,6.8003, time: 56s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#27/100 loss: 0.01131, brk: 0, vali: 24.496,2.5450,6.5561, time: 57s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#28/100 loss: 0.01144, brk: 1, vali: 24.442,2.7078,6.6612, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#29/100 loss: 0.01169, brk: 1, vali: 24.365,3.0852,6.9936, time: 56s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#30/100 loss: 0.01177, brk: 0, vali: 24.580,2.5253,6.5514, time: 57s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#31/100 loss: 0.01114, brk: 0, vali: 24.642,3.0266,6.9904, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#32/100 loss: 0.01095, brk: 1, vali: 24.503,2.6800,6.6478, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#33/100 loss: 0.01102, brk: 1, vali: 24.634,2.9119,6.8922, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#34/100 loss: 0.01128, brk: 1, vali: 24.526,3.2120,7.1325, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#35/100 loss: 0.01134, brk: 1, vali: 24.642,2.9030,6.9147, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#36/100 loss: 0.01105, brk: 0, vali: 25.397,3.2040,7.2772, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#37/100 loss: 0.01039, brk: 1, vali: 25.050,3.1483,7.1882, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#38/100 loss: 0.01058, brk: 1, vali: 25.219,3.2715,7.3067, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#39/100 loss: 0.01077, brk: 1, vali: 25.158,2.8471,6.9673, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#40/100 loss: 0.01086, brk: 0, vali: 25.574,3.2880,7.3851, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#41/100 loss: 0.01075, brk: 0, vali: 25.735,2.9214,7.1038, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#42/100 loss: 0.00999, brk: 0, vali: 25.920,3.0196,7.2159, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#43/100 loss: 0.01019, brk: 1, vali: 25.397,3.3282,7.3795, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#44/100 loss: 0.01042, brk: 1, vali: 25.335,3.2578,7.3041, time: 57s,9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#45/100 loss: 0.01049, brk: 1, vali: 25.535,3.3477,7.4081, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#46/100 loss: 0.01046, brk: 1, vali: 25.389,3.2767,7.3476, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#47/100 loss: 0.00973, brk: 1, vali: 25.913,3.2986,7.4619, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#48/100 loss: 0.00983, brk: 1, vali: 25.712,3.3785,7.4766, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#49/100 loss: 0.01013, brk: 1, vali: 25.682,3.6069,7.6770, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#50/100 loss: 0.01017, brk: 1, vali: 25.566,3.0879,7.2213, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#51/100 loss: 0.01028, brk: 1, vali: 25.065,3.1190,7.1470, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#52/100 loss: 0.00933, brk: 1, vali: 25.859,2.9866,7.1816, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#53/100 loss: 0.00969, brk: 1, vali: 25.866,2.9504,7.1890, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#54/100 loss: 0.00981, brk: 0, vali: 25.990,3.2235,7.4130, time: 57s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#55/100 loss: 0.00995, brk: 0, vali: 26.051,3.1310,7.3507, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#56/100 loss: 0.01017, brk: 1, vali: 25.928,3.3158,7.4892, time: 64s,9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#57/100 loss: 0.00930, brk: 1, vali: 25.682,3.4863,7.5989, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#58/100 loss: 0.00942, brk: 1, vali: 25.990,3.1337,7.3597, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#59/100 loss: 0.00974, brk: 1, vali: 25.997,3.4182,7.5714, time: 59s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#60/100 loss: 0.00964, brk: 1, vali: 25.735,3.3116,7.4692, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#61/100 loss: 0.00994, brk: 1, vali: 25.543,3.4600,7.5358, time: 58s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#62/100 loss: 0.00921, brk: 2, vali: 25.712,3.2824,7.4151, time: 62s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#63/100 loss: 0.00910, brk: 3, vali: 25.620,3.3699,7.5119, time: 58s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#64/100 loss: 0.00945, brk: 4, vali: 25.674,3.3063,7.4441, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#65/100 loss: 0.00972, brk: 5, vali: 25.920,3.1118,7.2880, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#66/100 loss: 0.00969, brk: 6, vali: 25.913,3.3974,7.5403, time: 64s,9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#67/100 loss: 0.00913, brk: 7, vali: 25.658,3.1509,7.3319, time: 66s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#68/100 loss: 0.00905, brk: 8, vali: 26.013,3.2375,7.4569, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#69/100 loss: 0.00924, brk: 9, vali: 25.936,3.3909,7.5621, time: 58s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#70/100 loss: 0.00938, brk: 0, vali: 26.251,3.3907,7.6184, time: 71s,12s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#71/100 loss: 0.00954, brk: 1, vali: 26.105,3.4663,7.6753, time: 58s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#72/100 loss: 0.00910, brk: 2, vali: 25.789,3.5568,7.6750, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#73/100 loss: 0.00902, brk: 3, vali: 25.535,3.3778,7.5082, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#74/100 loss: 0.00905, brk: 0, vali: 26.313,3.4974,7.7188, time: 57s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#75/100 loss: 0.00926, brk: 1, vali: 26.020,3.2607,7.4826, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#76/100 loss: 0.00950, brk: 2, vali: 26.113,3.3851,7.5641, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#77/100 loss: 0.00900, brk: 3, vali: 26.282,3.2059,7.4620, time: 57s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#78/100 loss: 0.00878, brk: 4, vali: 26.290,3.3371,7.5930, time: 61s,9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#79/100 loss: 0.00904, brk: 5, vali: 26.228,3.2655,7.5120, time: 64s,9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#80/100 loss: 0.00920, brk: 0, vali: 26.328,3.3967,7.6207, time: 60s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#81/100 loss: 0.00933, brk: 0, vali: 26.421,3.2744,7.5110, time: 61s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#82/100 loss: 0.00910, brk: 0, vali: 26.436,3.4467,7.6438, time: 61s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#83/100 loss: 0.00860, brk: 0, vali: 26.629,3.0225,7.3474, time: 61s,8s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#84/100 loss: 0.00885, brk: 1, vali: 26.498,3.3534,7.6055, time: 61s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#85/100 loss: 0.00901, brk: 2, vali: 25.805,3.4034,7.5452, time: 61s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#86/100 loss: 0.00920, brk: 3, vali: 26.513,3.1853,7.4962, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#87/100 loss: 0.00900, brk: 4, vali: 25.959,3.5934,7.7231, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#88/100 loss: 0.00852, brk: 5, vali: 26.467,3.3441,7.5912, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#89/100 loss: 0.00888, brk: 6, vali: 26.005,3.2720,7.4444, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#90/100 loss: 0.00897, brk: 7, vali: 26.267,3.3423,7.5830, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#91/100 loss: 0.00914, brk: 8, vali: 26.182,3.1882,7.4422, time: 61s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#92/100 loss: 0.00894, brk: 9, vali: 26.452,3.6844,7.9029, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#93/100 loss: 0.00853, brk: 10, vali: 26.144,3.3752,7.6028, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m#94/100 loss: 0.00857, brk: 0, vali: 26.675,3.5084,7.7858, time: 60s,9s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#95/100 loss: 0.00884, brk: 1, vali: 26.144,3.2121,7.4372, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#96/100 loss: 0.00896, brk: 2, vali: 26.205,3.0697,7.3443, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#97/100 loss: 0.00902, brk: 3, vali: 26.105,3.0892,7.3443, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#98/100 loss: 0.00841, brk: 4, vali: 25.735,3.2427,7.3862, time: 61s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#99/100 loss: 0.00850, brk: 5, vali: 25.951,2.9614,7.2157, time: 60s,8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#100/100 loss: 0.00881, brk: 6, vali: 26.652,3.1499,7.4995, time: 60s,8s\n",
      "INFO:tensorflow:Restoring parameters from run_time/save/2023-05-17_12.49.50.4390-GNN-yc/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m\n",
      "test: 26.685,3.4416,7.7391\n",
      "\u001b[0m\n",
      "run_time/log/2023-05-17_12.49.50.4390-GNN-yc.log\n",
      "end time: 2023-05-17_14.41.31.2552, dt: 1.90h\n",
      "2023-05-17_14.41.31.2552 run_time/log/2023-05-17_12.49.50.4390-GNN-yc.log ##### over, time: 1.90h\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import Train\n",
    "# import dataset_online as dataset\n",
    "import dataset\n",
    "import models\n",
    "import util\n",
    "from util import args\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    parser.add_argument('-show_test', action='store_true')\n",
    "    parser.add_argument('-run_tb', action='store_true')\n",
    "    parser.add_argument('-run_test', action='store_true')\n",
    "    parser.add_argument('-epochs', type=int, default=100)\n",
    "    parser.add_argument('-es', '--early_stopping', type=int, default=30)\n",
    "    parser.add_argument('-valistep', '--nb_vali_step', type=int, default=500)\n",
    "    parser.add_argument('-bs', '--batch_size', type=int, default=64)\n",
    "    parser.add_argument('-seed', type=int, default=123456)\n",
    "    parser.add_argument('-gpu', type=str, default='0')\n",
    "    parser.add_argument('-ds', type=str, default='yc')\n",
    "    parser.add_argument('-verbose', type=int, default=1)\n",
    "    parser.add_argument('-msg', type=str, default='')\n",
    "    # parser.add_argument('-restore_model', type = str, default = '')\n",
    "    parser.add_argument('-model', type=str, default='GNN')\n",
    "\n",
    "    parser.add_argument('-k', '--dim_k', type=int, default=64)\n",
    "    parser.add_argument('-lr', type=float, default=1e-3)\n",
    "    parser.add_argument('-l2_all', type=float, default=0)\n",
    "\n",
    "    parser.add_argument('-seq_length', type=int, default=20)\n",
    "    parser.add_argument('-adj_length', type=int, default=22)\n",
    "    parser.add_argument('-num_neg', type=int, default=20)\n",
    "\n",
    "    parser.add_argument('-gnnd', type=int, default=1)\n",
    "\n",
    "    #a = parser.parse_args().__dict__\n",
    "    arg, unknown = parser.parse_known_args()\n",
    "    a = arg.__dict__\n",
    "    return a\n",
    "\n",
    "\n",
    "def main(**main_args):\n",
    "    begin_time = time.time()\n",
    "\n",
    "    # init args\n",
    "    args.update(**main_args)\n",
    "    command_line_args = parse_args()\n",
    "    args.setdefault(**command_line_args)\n",
    "\n",
    "    args.update(run_on_yard=True)\n",
    "\n",
    "    seed = args.seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "    # get Model, set model default args\n",
    "    Model = vars(models)[args.model]\n",
    "    args.setdefault(**Model.args.vars())\n",
    "    #args.setdefault(**GNN.args.vars())\n",
    "\n",
    "    if args.run_test:\n",
    "        args.update(epochs=2, nb_vali_step=2, max_data_line=100)\n",
    "\n",
    "    print(args)\n",
    "\n",
    "\n",
    "    # get data\n",
    "    random.seed(seed)\n",
    "    np.random.seed(args.seed)\n",
    "    data = Data()\n",
    "    min_epochs = args.nb_train / (args.batch_size * args.nb_vali_step)\n",
    "    if min_epochs < 1.0:\n",
    "        args.update(nb_vali_step=int(np.ceil(args.nb_train / args.batch_size)))\n",
    "        print(args)\n",
    "        min_epochs = args.nb_train / (args.batch_size * args.nb_vali_step)\n",
    "    args.update(min_epochs=int(np.ceil(min_epochs)))\n",
    "    # args.setdefault())\n",
    "\n",
    "    # run_name: time-x-Modes-ds\n",
    "    time_str = get_time_str()\n",
    "    model_name = Model.__name__\n",
    "    #model_name = 'GNN'\n",
    "    run_name = f'{time_str}-{model_name}-{args.ds}'\n",
    "    if args.msg:\n",
    "        run_name = f'{run_name}-{args.msg}'\n",
    "    if args.run_test:\n",
    "        run_name = f'{run_name}-test'\n",
    "\n",
    "    args.update(run_name=run_name)\n",
    "    #T =Train(Model, data)\n",
    "    T =Train.Train(GNN, data)\n",
    "\n",
    "    log_fn = f'{log_dir}/{run_name}.log'\n",
    "    begin_time_str = get_time_str()\n",
    "    print(begin_time_str, log_fn, '----- start!, pid:', os.getpid())\n",
    "    args.update(pid=os.getpid())\n",
    "    log = Logger(fn=log_fn, verbose=args.verbose)\n",
    "    args.update(log=log)\n",
    "    args.log.log(f'argv: {\" \".join(sys.argv)}')\n",
    "    args.log.log(f'log_fn: {log_fn}')\n",
    "    args.log.log(f'args: {args.prt_json()}')\n",
    "    args.log.log(f'Model: {model_name}')\n",
    "    args.log.log(f'begin time: {begin_time_str}')\n",
    "\n",
    "    try:\n",
    "        T.train()\n",
    "    except KeyboardInterrupt as e:\n",
    "        if not T.has_train:\n",
    "            raise e\n",
    "    test_str = T.final_test()\n",
    "\n",
    "    args.log.log(f'\\ntest: {test_str}\\n', red=True)\n",
    "\n",
    "\n",
    "    args.log.log(log_fn)\n",
    "    dt = time.time() - begin_time\n",
    "    end_time_str = get_time_str()\n",
    "    args.log.log(f'end time: {end_time_str}, dt: {dt / 3600:.2f}h')\n",
    "    print(end_time_str, log_fn, f'##### over, time: {dt / 3600:.2f}h')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(os.getcwd())\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
